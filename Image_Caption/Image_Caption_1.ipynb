{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KixwxPb3Dq9_",
        "abNFp4kID0Y6"
      ],
      "authorship_tag": "ABX9TyPRxEAvakiik9Sry/mpGbm0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkitaGuptaIndia/Course_6_Image_Caption/blob/main/Image_Caption/Image_Caption_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a clone of the Repo"
      ],
      "metadata": {
        "id": "KixwxPb3Dq9_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x1Uk1opjoF6",
        "outputId": "a810bdb8-e279-43bf-be21-cb3eee62f2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Course_6_Image_Caption'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 21 (delta 5), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (21/21), 166.69 KiB | 2.98 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AnkitaGuptaIndia/Course_6_Image_Caption.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Course_6_Image_Caption"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7om60d0Jjr2-",
        "outputId": "9c079126-0feb-482c-adda-c9a3891ec79d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Course_6_Image_Caption\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJPX_TgJjxYe",
        "outputId": "34070716-0ace-41b5-c2f7-c69253fd46a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_1.jpg  Image_Caption  notebooks  README.md  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Image Generation Code - 1"
      ],
      "metadata": {
        "id": "abNFp4kID0Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "rSMI0ox3kMbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the processor and model from HuggingFace\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
      ],
      "metadata": {
        "id": "avO7XfE7kYKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an image\n",
        "image = Image.open(\"image_1.jpg\")"
      ],
      "metadata": {
        "id": "WFucUgwYk6yR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the Image\n",
        "inputs = processor(image, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "Ea6sgOtOlhYy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate caption\n",
        "outputs = model.generate(**inputs)\n",
        "caption = processor.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "kNK5bhzbl496"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generated Caption:\", caption)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El-baK7xmGwW",
        "outputId": "c7098997-e766-483f-f49e-1006b6d36b8e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption: a view of the mountains from an airplane\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Image Generation Code - 2"
      ],
      "metadata": {
        "id": "EDwbyNceiUGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "oKKhz8iSi2dE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the processor and model from HuggingFace\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")"
      ],
      "metadata": {
        "id": "AEcVTHVNiWNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg'\n",
        "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
        "question = \"What is in the image?\""
      ],
      "metadata": {
        "id": "xrxFhvrciWH2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
        "out = model.generate(**inputs)\n",
        "answer = processor.decode(out[0], skip_special_tokens=True)\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0DiAF-tjSVV",
        "outputId": "84b10ca3-e7a7-431d-e093-ae3d2aaeb8eb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: what is in the image? a woman and her dog on the beach\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(image, question, return_tensors=\"pt\")\n",
        "out = model.generate(**inputs)\n",
        "answer = processor.decode(out[0], skip_special_tokens=True)\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7soij-Sje6v",
        "outputId": "2152c891-223f-4e51-9f0f-47d2453b9a4e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: what is in the image? a view of a mountain range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio Introduction"
      ],
      "metadata": {
        "id": "pb1fw9_ykCN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "pImh99pekG5t"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name, intensity):\n",
        "  return \"Hello, \" + name + \"!\" * int(intensity)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn = greet,\n",
        "    inputs = [\"text\", \"slider\"],\n",
        "    outputs = [\"text\"]\n",
        ")"
      ],
      "metadata": {
        "id": "-0BRwO4JkG2J"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(server_name=\"127.0.0.1\", server_port=7860)"
      ],
      "metadata": {
        "id": "ukLpJeVZkGx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z50-oHmHq8P9",
        "outputId": "b3a96f18-ea02-4727-8d55-0869e660fb85"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio For Image Captioning"
      ],
      "metadata": {
        "id": "ZDrVEBBUlUQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
      ],
      "metadata": {
        "id": "MMUzE3ytlWgb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_caption(image):\n",
        "  inputs = processor(images=image, return_tensors=\"pt\")\n",
        "  outputs = model.generate(**inputs)\n",
        "  caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
        "  return caption"
      ],
      "metadata": {
        "id": "ulSGqk1elWXF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caption_image(image):\n",
        "  try:\n",
        "    caption = generate_caption(image)\n",
        "    return caption\n",
        "  except Exception as e:\n",
        "    return f\"An error occurred: {str(e)}\""
      ],
      "metadata": {
        "id": "W5S0AnubmI9Q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface(\n",
        "    fn = caption_image,\n",
        "    inputs = gr.Image(type=\"pil\"),\n",
        "    outputs=\"text\",\n",
        "    title = \"Image Captioning with BLIP\",\n",
        "    description = \"Upload an image to generate a caption.\"\n",
        ")"
      ],
      "metadata": {
        "id": "LVbL_tUHmh-K"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch(server_name=\"127.0.0.1\", server_port= 5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "yGfKTAP1kGsF",
        "outputId": "3a71990f-3c79-4a03-fb59-9b67e57ff50e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://185d261e2e361dbc59.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://185d261e2e361dbc59.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iface.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "630LhInLq4mq",
        "outputId": "6be883bc-1315-4c6e-d54f-35586f119a67"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Classification in PyTorch"
      ],
      "metadata": {
        "id": "XH2nhA7voJMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "pe6nS3hooKiN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()"
      ],
      "metadata": {
        "id": "luWwZ5C3oVwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "e-b36NaPoVsA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download human readable labels for ImageNet\n",
        "response = requests.get(\"https://git.io/JJkYN\")\n",
        "labels = response.text.split(\"\\n\")"
      ],
      "metadata": {
        "id": "wwpH6Rh7oVnK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(inp):\n",
        "  inp = transforms.ToTensor()(inp).unsqueeze(0)\n",
        "  with torch.no_grad():\n",
        "    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n",
        "    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n",
        "  return confidences"
      ],
      "metadata": {
        "id": "_WfuVuHSoVg7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface_2 = gr.Interface(\n",
        "    fn = predict,\n",
        "    inputs = gr.Image(type = \"pil\"),\n",
        "    outputs = gr.Label(num_top_classes=3),\n",
        "    examples = [\"/content/lion.jpg\", \"/content/cheetah.jpg\"]\n",
        ")"
      ],
      "metadata": {
        "id": "M3Bk8FwIpw0q"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface_2.launch(server_name=\"127.0.0.1\", server_port=7860)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "e0HjSGzIoVY1",
        "outputId": "8edcfb83-32e7-4898-95af-96d7f6fa663e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fccd52ccf0e5face71.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fccd52ccf0e5face71.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iface_2.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9azDZUeNrDpN",
        "outputId": "3521c410-a2eb-4b18-ead0-2d106d994a83"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pushing the code back to the repo"
      ],
      "metadata": {
        "id": "a75qSVqMEJDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "Ci3GUFJmmHXb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"ankitagpt32.ag@gmail.com\"\n",
        "!git config --global user.name \"AnkitaGuptaIndia\""
      ],
      "metadata": {
        "id": "P7XdNhJtC6y0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Basic Image Generation Code\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN8qFyyxERK6",
        "outputId": "563823eb-10b3-47f5-9c9a-9c5f8816ace1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push <token_url>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u14ywoEXEVaI",
        "outputId": "5d5b8082-6196-4dc3-b756-cafe86a70699"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vzolV9QvEgq3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}